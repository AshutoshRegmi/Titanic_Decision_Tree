{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import math\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/ashutoshregmi/ML_Prac/Titanic_Decision_Tree/Titanic-Dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TITANIC DATASET ANALYSIS ===\n",
      "Dataset shape: (891, 12)\n",
      "Survival rate: 0.384\n",
      "\n",
      "=== SURVIVAL PATTERNS ===\n",
      "\n",
      "By Sex:\n",
      "        Total  Survived   Rate\n",
      "Sex                           \n",
      "female    314       233  0.742\n",
      "male      577       109  0.189\n",
      "\n",
      "By Class:\n",
      "        Total  Survived   Rate\n",
      "Pclass                        \n",
      "1         216       136  0.630\n",
      "2         184        87  0.473\n",
      "3         491       119  0.242\n",
      "\n",
      "By Sex and Class:\n",
      "               Total  Survived   Rate\n",
      "Sex    Pclass                        \n",
      "female 1          94        91  0.968\n",
      "       2          76        70  0.921\n",
      "       3         144        72  0.500\n",
      "male   1         122        45  0.369\n",
      "       2         108        17  0.157\n",
      "       3         347        47  0.135\n"
     ]
    }
   ],
   "source": [
    "print(\"=== TITANIC DATASET ANALYSIS ===\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Survival rate: {df['Survived'].mean():.3f}\")\n",
    "\n",
    "print(\"\\n=== SURVIVAL PATTERNS ===\")\n",
    "print(\"\\nBy Sex:\")\n",
    "sex_survival = df.groupby('Sex')['Survived'].agg(['count', 'sum', lambda x: x.mean()]).round(3)\n",
    "sex_survival.columns = ['Total', 'Survived', 'Rate']\n",
    "print(sex_survival)\n",
    "\n",
    "print(\"\\nBy Class:\")\n",
    "class_survival = df.groupby('Pclass')['Survived'].agg(['count', 'sum', lambda x: x.mean()]).round(3)\n",
    "class_survival.columns = ['Total', 'Survived', 'Rate']\n",
    "print(class_survival)\n",
    "\n",
    "print(\"\\nBy Sex and Class:\")\n",
    "sex_class_survival = df.groupby(['Sex', 'Pclass'])['Survived'].agg(['count', 'sum', lambda x: x.mean()]).round(3)\n",
    "sex_class_survival.columns = ['Total', 'Survived', 'Rate']\n",
    "print(sex_class_survival)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Children (<18): 61/113 survived (0.540)\n",
      "Adults (18+): 229/601 survived (0.381)\n"
     ]
    }
   ],
   "source": [
    "# Age analysis\n",
    "df_age = df.dropna(subset=['Age'])\n",
    "children = df_age[df_age['Age'] < 18]\n",
    "adults = df_age[df_age['Age'] >= 18]\n",
    "print(f\"\\nChildren (<18): {children['Survived'].sum()}/{len(children)} survived ({children['Survived'].mean():.3f})\")\n",
    "print(f\"Adults (18+): {adults['Survived'].sum()}/{len(adults)} survived ({adults['Survived'].mean():.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Node Class\n",
    "class DecisionNode:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None, samples=0):\n",
    "        self.feature = feature      # Feature to split on\n",
    "        self.threshold = threshold  # Threshold value for split\n",
    "        self.left = left           # Left subtree\n",
    "        self.right = right         # Right subtree  \n",
    "        self.value = value         # Prediction value (for leaf nodes)\n",
    "        self.samples = samples     # Number of samples in this node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Implementation\n",
    "class HandMadeDecisionTree:\n",
    "    def __init__(self, max_depth=5, min_samples_split=10):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.root = None\n",
    "        \n",
    "    def entropy(self, y):\n",
    "        \"\"\"Calculate entropy of target variable\"\"\"\n",
    "        if len(y) == 0:\n",
    "            return 0\n",
    "        \n",
    "        counts = Counter(y)\n",
    "        probs = [count / len(y) for count in counts.values()]\n",
    "        entropy = -sum(p * math.log2(p) for p in probs if p > 0)\n",
    "        return entropy\n",
    "    \n",
    "    def information_gain(self, X, y, feature, threshold):\n",
    "        \"\"\"Calculate information gain for a split\"\"\"\n",
    "        # Parent entropy\n",
    "        parent_entropy = self.entropy(y)\n",
    "        \n",
    "        # Split the data\n",
    "        if X[feature].dtype in ['object', 'category']:\n",
    "            # Categorical split\n",
    "            left_mask = X[feature] == threshold\n",
    "        else:\n",
    "            # Numerical split\n",
    "            left_mask = X[feature] <= threshold\n",
    "            \n",
    "        right_mask = ~left_mask\n",
    "        \n",
    "        # Check if split is valid\n",
    "        if sum(left_mask) == 0 or sum(right_mask) == 0:\n",
    "            return 0\n",
    "        \n",
    "        # Calculate weighted entropy of children\n",
    "        n = len(y)\n",
    "        left_entropy = self.entropy(y[left_mask])\n",
    "        right_entropy = self.entropy(y[right_mask])\n",
    "        \n",
    "        weighted_entropy = (sum(left_mask) / n) * left_entropy + (sum(right_mask) / n) * right_entropy\n",
    "        \n",
    "        return parent_entropy - weighted_entropy\n",
    "    \n",
    "    def find_best_split(self, X, y):\n",
    "        \"\"\"Find the best feature and threshold to split on\"\"\"\n",
    "        best_gain = -1\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        \n",
    "        # Try each feature\n",
    "        for feature in X.columns:\n",
    "            if feature in ['PassengerId', 'Name', 'Ticket', 'Cabin']:\n",
    "                continue  # Skip non-predictive features\n",
    "                \n",
    "            if X[feature].dtype in ['object', 'category']:\n",
    "                # Categorical feature\n",
    "                unique_values = X[feature].dropna().unique()\n",
    "                for value in unique_values:\n",
    "                    gain = self.information_gain(X, y, feature, value)\n",
    "                    if gain > best_gain:\n",
    "                        best_gain = gain\n",
    "                        best_feature = feature\n",
    "                        best_threshold = value\n",
    "            else:\n",
    "                # Numerical feature\n",
    "                sorted_values = sorted(X[feature].dropna().unique())\n",
    "                for i in range(len(sorted_values) - 1):\n",
    "                    threshold = (sorted_values[i] + sorted_values[i + 1]) / 2\n",
    "                    gain = self.information_gain(X, y, feature, threshold)\n",
    "                    if gain > best_gain:\n",
    "                        best_gain = gain\n",
    "                        best_feature = feature\n",
    "                        best_threshold = threshold\n",
    "        \n",
    "        return best_feature, best_threshold, best_gain\n",
    "    \n",
    "    def build_tree(self, X, y, depth=0):\n",
    "        \"\"\"Recursively build the decision tree\"\"\"\n",
    "        n_samples = len(y)\n",
    "        \n",
    "        # Stopping conditions\n",
    "        if (depth >= self.max_depth or \n",
    "            n_samples < self.min_samples_split or \n",
    "            len(set(y)) == 1):\n",
    "            # Create leaf node\n",
    "            most_common = Counter(y).most_common(1)[0][0]\n",
    "            return DecisionNode(value=most_common, samples=n_samples)\n",
    "        \n",
    "        # Find best split\n",
    "        best_feature, best_threshold, best_gain = self.find_best_split(X, y)\n",
    "        \n",
    "        if best_gain <= 0:\n",
    "            # No good split found, create leaf\n",
    "            most_common = Counter(y).most_common(1)[0][0]\n",
    "            return DecisionNode(value=most_common, samples=n_samples)\n",
    "        \n",
    "        # Split the data\n",
    "        if X[best_feature].dtype in ['object', 'category']:\n",
    "            left_mask = X[best_feature] == best_threshold\n",
    "        else:\n",
    "            left_mask = X[best_feature] <= best_threshold\n",
    "            \n",
    "        right_mask = ~left_mask\n",
    "        \n",
    "        # Create child nodes\n",
    "        left_child = self.build_tree(X[left_mask], y[left_mask], depth + 1)\n",
    "        right_child = self.build_tree(X[right_mask], y[right_mask], depth + 1)\n",
    "        \n",
    "        return DecisionNode(\n",
    "            feature=best_feature,\n",
    "            threshold=best_threshold,\n",
    "            left=left_child,\n",
    "            right=right_child,\n",
    "            samples=n_samples\n",
    "        )\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Train the decision tree\"\"\"\n",
    "        self.root = self.build_tree(X, y.values)\n",
    "    \n",
    "    def predict_single(self, x, node):\n",
    "        \"\"\"Make prediction for a single sample\"\"\"\n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "        \n",
    "        feature_value = x[node.feature]\n",
    "        \n",
    "        # Handle missing values\n",
    "        if pd.isna(feature_value):\n",
    "            # Go to the child with more samples (majority)\n",
    "            if node.left.samples >= node.right.samples:\n",
    "                return self.predict_single(x, node.left)\n",
    "            else:\n",
    "                return self.predict_single(x, node.right)\n",
    "        \n",
    "        # Navigate tree\n",
    "        if isinstance(node.threshold, str):\n",
    "            # Categorical\n",
    "            if feature_value == node.threshold:\n",
    "                return self.predict_single(x, node.left)\n",
    "            else:\n",
    "                return self.predict_single(x, node.right)\n",
    "        else:\n",
    "            # Numerical\n",
    "            if feature_value <= node.threshold:\n",
    "                return self.predict_single(x, node.left)\n",
    "            else:\n",
    "                return self.predict_single(x, node.right)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions for multiple samples\"\"\"\n",
    "        predictions = []\n",
    "        for _, row in X.iterrows():\n",
    "            pred = self.predict_single(row, self.root)\n",
    "            predictions.append(pred)\n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def print_tree(self, node=None, depth=0):\n",
    "        \"\"\"Print the tree structure\"\"\"\n",
    "        if node is None:\n",
    "            node = self.root\n",
    "            \n",
    "        if node.value is not None:\n",
    "            print(\"  \" * depth + f\"Predict: {node.value} (samples: {node.samples})\")\n",
    "        else:\n",
    "            if isinstance(node.threshold, str):\n",
    "                print(\"  \" * depth + f\"If {node.feature} == '{node.threshold}' (samples: {node.samples}):\")\n",
    "            else:\n",
    "                print(\"  \" * depth + f\"If {node.feature} <= {node.threshold:.2f} (samples: {node.samples}):\")\n",
    "            \n",
    "            self.print_tree(node.left, depth + 1)\n",
    "            \n",
    "            if isinstance(node.threshold, str):\n",
    "                print(\"  \" * depth + f\"Else {node.feature} != '{node.threshold}':\")\n",
    "            else:\n",
    "                print(\"  \" * depth + f\"Else {node.feature} > {node.threshold:.2f}:\")\n",
    "            \n",
    "            self.print_tree(node.right, depth + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hand-Crafted Rules Decision Tree (Based on Analysis)\n",
    "class SimpleTitanicRules:\n",
    "    \"\"\"\n",
    "    Simple rule-based classifier based on observed patterns:\n",
    "    - Women have 74.2% survival rate\n",
    "    - Men have 18.9% survival rate  \n",
    "    - Children have better survival rates\n",
    "    - First class has better survival rates\n",
    "    \"\"\"\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for _, row in X.iterrows():\n",
    "            # Rule 1: Women more likely to survive\n",
    "            if row['Sex'] == 'female':\n",
    "                predictions.append(1)\n",
    "            # Rule 2: Male children more likely to survive\n",
    "            elif row['Sex'] == 'male' and pd.notna(row.get('Age')) and row['Age'] < 18:\n",
    "                predictions.append(1)\n",
    "            # Rule 3: First class males have better chances\n",
    "            elif row['Sex'] == 'male' and row['Pclass'] == 1:\n",
    "                predictions.append(1)\n",
    "            else:\n",
    "                predictions.append(0)\n",
    "        \n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def print_rules(self):\n",
    "        print(\"\\n=== HAND-CRAFTED DECISION RULES ===\")\n",
    "        print(\"1. If passenger is female → SURVIVED\")\n",
    "        print(\"2. If passenger is male AND age < 18 → SURVIVED\") \n",
    "        print(\"3. If passenger is male AND class = 1 → SURVIVED\")\n",
    "        print(\"4. Otherwise → NOT SURVIVED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8n/9r6bjsb57dv1kw36g6dpkdbc0000gn/T/ipykernel_14454/583659058.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Age'].fillna(df['Age'].median(), inplace=True)\n",
      "/var/folders/8n/9r6bjsb57dv1kw36g6dpkdbc0000gn/T/ipykernel_14454/583659058.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X['Embarked'].fillna(X['Embarked'].mode()[0], inplace=True)\n",
      "/var/folders/8n/9r6bjsb57dv1kw36g6dpkdbc0000gn/T/ipykernel_14454/583659058.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X['Fare'].fillna(X['Fare'].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for modeling\n",
    "# Fill missing ages with median\n",
    "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
    "\n",
    "# Select features for the tree\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "X = df[features].copy()\n",
    "\n",
    "# Fill missing values\n",
    "X['Embarked'].fillna(X['Embarked'].mode()[0], inplace=True)\n",
    "X['Fare'].fillna(X['Fare'].median(), inplace=True)\n",
    "\n",
    "y = df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MODEL TRAINING ===\n",
      "Training set size: 712\n",
      "Test set size: 179\n",
      "\n",
      "Training hand-made decision tree...\n",
      "\n",
      "=== HAND-CRAFTED DECISION RULES ===\n",
      "1. If passenger is female → SURVIVED\n",
      "2. If passenger is male AND age < 18 → SURVIVED\n",
      "3. If passenger is male AND class = 1 → SURVIVED\n",
      "4. Otherwise → NOT SURVIVED\n"
     ]
    }
   ],
   "source": [
    "# Split data manually (80-20 split)\n",
    "np.random.seed(42)\n",
    "indices = np.random.permutation(len(X))\n",
    "train_size = int(0.8 * len(X))\n",
    "train_indices = indices[:train_size]\n",
    "test_indices = indices[train_size:]\n",
    "\n",
    "X_train = X.iloc[train_indices].reset_index(drop=True)\n",
    "X_test = X.iloc[test_indices].reset_index(drop=True)\n",
    "y_train = y.iloc[train_indices].reset_index(drop=True)\n",
    "y_test = y.iloc[test_indices].reset_index(drop=True)\n",
    "\n",
    "print(\"\\n=== MODEL TRAINING ===\")\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "\n",
    "# Train the hand-made decision tree\n",
    "print(\"\\nTraining hand-made decision tree...\")\n",
    "tree = HandMadeDecisionTree(max_depth=5, min_samples_split=10)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# Train the simple rules classifier\n",
    "rules_classifier = SimpleTitanicRules()\n",
    "rules_classifier.print_rules()\n",
    "\n",
    "# Make predictions\n",
    "tree_pred_train = tree.predict(X_train)\n",
    "tree_pred_test = tree.predict(X_test)\n",
    "\n",
    "rules_pred_train = rules_classifier.predict(X_train)\n",
    "rules_pred_test = rules_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy manually\n",
    "def accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "def confusion_matrix_manual(y_true, y_pred):\n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    tn = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    return np.array([[tn, fp], [fn, tp]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESULTS ===\n",
      "\n",
      "Decision Tree Performance:\n",
      "Training Accuracy: 0.844\n",
      "Test Accuracy: 0.844\n",
      "\n",
      "Simple Rules Performance:\n",
      "Training Accuracy: 0.730\n",
      "Test Accuracy: 0.743\n",
      "\n",
      "=== DECISION TREE STRUCTURE ===\n",
      "If Sex == 'male' (samples: 712):\n",
      "  If Fare <= 26.27 (samples: 459):\n",
      "    If Age <= 13.50 (samples: 334):\n",
      "      If SibSp <= 2.00 (samples: 12):\n",
      "        If Age <= 10.00 (samples: 11):\n",
      "          Predict: 1 (samples: 9)\n",
      "        Else Age > 10.00:\n",
      "          Predict: 1 (samples: 2)\n",
      "      Else SibSp > 2.00:\n",
      "        Predict: 0 (samples: 1)\n",
      "    Else Age > 13.50:\n",
      "      If Age <= 32.50 (samples: 322):\n",
      "        If Age <= 30.75 (samples: 243):\n",
      "          Predict: 0 (samples: 229)\n",
      "        Else Age > 30.75:\n",
      "          Predict: 0 (samples: 14)\n",
      "      Else Age > 32.50:\n",
      "        If Fare <= 11.39 (samples: 79):\n",
      "          Predict: 0 (samples: 45)\n",
      "        Else Fare > 11.39:\n",
      "          Predict: 0 (samples: 34)\n",
      "  Else Fare > 26.27:\n",
      "    If SibSp <= 2.50 (samples: 125):\n",
      "      If Age <= 13.50 (samples: 108):\n",
      "        Predict: 1 (samples: 7)\n",
      "      Else Age > 13.50:\n",
      "        If Age <= 53.00 (samples: 101):\n",
      "          Predict: 0 (samples: 84)\n",
      "        Else Age > 53.00:\n",
      "          Predict: 0 (samples: 17)\n",
      "    Else SibSp > 2.50:\n",
      "      If Age <= 3.50 (samples: 17):\n",
      "        Predict: 0 (samples: 5)\n",
      "      Else Age > 3.50:\n",
      "        Predict: 0 (samples: 12)\n",
      "Else Sex != 'male':\n",
      "  If Pclass <= 2.50 (samples: 253):\n",
      "    If Fare <= 28.86 (samples: 139):\n",
      "      If Fare <= 28.23 (samples: 58):\n",
      "        If Age <= 23.50 (samples: 57):\n",
      "          Predict: 1 (samples: 11)\n",
      "        Else Age > 23.50:\n",
      "          Predict: 1 (samples: 46)\n",
      "      Else Fare > 28.23:\n",
      "        Predict: 0 (samples: 1)\n",
      "    Else Fare > 28.86:\n",
      "      If Age <= 2.50 (samples: 81):\n",
      "        Predict: 0 (samples: 1)\n",
      "      Else Age > 2.50:\n",
      "        Predict: 1 (samples: 80)\n",
      "  Else Pclass > 2.50:\n",
      "    If Fare <= 22.90 (samples: 114):\n",
      "      If Age <= 6.50 (samples: 89):\n",
      "        If SibSp <= 2.50 (samples: 11):\n",
      "          Predict: 1 (samples: 10)\n",
      "        Else SibSp > 2.50:\n",
      "          Predict: 0 (samples: 1)\n",
      "      Else Age > 6.50:\n",
      "        If Fare <= 8.04 (samples: 78):\n",
      "          Predict: 1 (samples: 34)\n",
      "        Else Fare > 8.04:\n",
      "          Predict: 0 (samples: 44)\n",
      "    Else Fare > 22.90:\n",
      "      If Parch <= 0.50 (samples: 25):\n",
      "        Predict: 1 (samples: 1)\n",
      "      Else Parch > 0.50:\n",
      "        If Fare <= 31.33 (samples: 24):\n",
      "          Predict: 0 (samples: 14)\n",
      "        Else Fare > 31.33:\n",
      "          Predict: 0 (samples: 10)\n",
      "\n",
      "=== CONFUSION MATRICES ===\n",
      "\n",
      "Decision Tree - Test Set:\n",
      "True Negatives: 107, False Positives: 7\n",
      "False Negatives: 21, True Positives: 44\n",
      "\n",
      "Simple Rules - Test Set:\n",
      "True Negatives: 75, False Positives: 39\n",
      "False Negatives: 7, True Positives: 58\n",
      "\n",
      "=== FEATURE ANALYSIS ===\n",
      "Most important patterns observed:\n",
      "1. Sex is the strongest predictor (74.2% vs 18.9% survival)\n",
      "2. Class matters significantly (63.0% vs 47.3% vs 24.2%)\n",
      "3. Age affects survival (children have 54.0% vs adults 38.1%)\n",
      "4. Combined effects: Female + First Class = 96.8% survival\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== RESULTS ===\")\n",
    "print(\"\\nDecision Tree Performance:\")\n",
    "print(f\"Training Accuracy: {accuracy(y_train, tree_pred_train):.3f}\")\n",
    "print(f\"Test Accuracy: {accuracy(y_test, tree_pred_test):.3f}\")\n",
    "\n",
    "print(\"\\nSimple Rules Performance:\")\n",
    "print(f\"Training Accuracy: {accuracy(y_train, rules_pred_train):.3f}\")\n",
    "print(f\"Test Accuracy: {accuracy(y_test, rules_pred_test):.3f}\")\n",
    "\n",
    "print(\"\\n=== DECISION TREE STRUCTURE ===\")\n",
    "tree.print_tree()\n",
    "\n",
    "# Confusion matrices\n",
    "print(\"\\n=== CONFUSION MATRICES ===\")\n",
    "print(\"\\nDecision Tree - Test Set:\")\n",
    "cm_tree = confusion_matrix_manual(y_test, tree_pred_test)\n",
    "print(f\"True Negatives: {cm_tree[0,0]}, False Positives: {cm_tree[0,1]}\")\n",
    "print(f\"False Negatives: {cm_tree[1,0]}, True Positives: {cm_tree[1,1]}\")\n",
    "\n",
    "print(\"\\nSimple Rules - Test Set:\")\n",
    "cm_rules = confusion_matrix_manual(y_test, rules_pred_test)\n",
    "print(f\"True Negatives: {cm_rules[0,0]}, False Positives: {cm_rules[0,1]}\")\n",
    "print(f\"False Negatives: {cm_rules[1,0]}, True Positives: {cm_rules[1,1]}\")\n",
    "\n",
    "# Feature importance (manual calculation)\n",
    "print(\"\\n=== FEATURE ANALYSIS ===\")\n",
    "print(\"Most important patterns observed:\")\n",
    "print(\"1. Sex is the strongest predictor (74.2% vs 18.9% survival)\")\n",
    "print(\"2. Class matters significantly (63.0% vs 47.3% vs 24.2%)\")  \n",
    "print(\"3. Age affects survival (children have 54.0% vs adults 38.1%)\")\n",
    "print(\"4. Combined effects: Female + First Class = 96.8% survival\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
